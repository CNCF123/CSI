注意：1）CephFS的快照功能需要Ceph版本为O版；2）创建了快照的pvc挂载需要内核4.14版本。
快照功能需要安装快照控制器支持：

克隆代码

# git clone https://github.com/kubernetes-csi/external-snapshotter
# cd external-snapshotter/deploy/kubernetes/snapshot-controller

部署

# kubectl external-snapshotter/deploy/kubernetes/snapshot-controller/
# kubectl get pods | grep snapshot-controller
snapshot-controller-0                           1/1     Running   0          20h

部署crd

# kubectl apply -f external-snapshotter/config/crd/
# kubectl api-versions | grep snapshot
snapshot.storage.k8s.io/v1beta1
至此，Ceph-CSI和snapshot-controller安装完成。下面进行功能测试。测试功能前需要在ceph集群中创建对应的存储池：

创建rbd类型pvc的快照，并验证基于快照恢复的可用性：

创建上一步pvc的快照

# cat snapshot.yaml
---
apiVersion: snapshot.storage.k8s.io/v1beta1
kind: VolumeSnapshot
metadata:
  name: rbd-pvc-snapshot
spec:
  volumeSnapshotClassName: csi-rbdplugin-snapclass
  source:
    persistentVolumeClaimName: rbd-pvc
 
# kubectl apply -f snapshot.yaml
# kubectl get VolumeSnapshot rbd-pvc-snapshot
NAME               READYTOUSE   SOURCEPVC   SOURCESNAPSHOTCONTENT   RESTORESIZE   SNAPSHOTCLASS             SNAPSHOTCONTENT                                    CREATIONTIME   AGE
rbd-pvc-snapshot   true         rbd-pvc                             1Gi           csi-rbdplugin-snapclass   snapcontent-48f3e563-d21a-40bb-8e15-ddbf27886c88   19h            19h

创建基于快照恢复的pvc

# cat pvc-restore.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: rbd-pvc-restore
spec:
  storageClassName: csi-rbd-sc
  dataSource:
    name: rbd-pvc-snapshot
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
 
# kubectl apply -f pvc-restore.yaml


创建pod应用快照恢复的pvc

# cat pod-restore.yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: csi-rbd-restore-demo-pod
spec:
  containers:
    - name: web-server
      image: nginx
      volumeMounts:
        - name: mypvc
          mountPath: /var/lib/www/html
  volumes:
    - name: mypvc
      persistentVolumeClaim:
        claimName: rbd-pvc-restore
        readOnly: false
 
# kubectl apply -f pod-restore.yaml
# kubectl get pods csi-rbd-restore-demo-pod
NAME                       READY   STATUS    RESTARTS   AGE
csi-rbd-restore-demo-pod   1/1     Running   0          18h
# kubectl exec -ti csi-rbd-restore-demo-pod -- bash
root@csi-rbd-restore-demo-pod:/# df -h
Filesystem               Size  Used Avail Use% Mounted on
overlay                  199G  7.4G  192G   4% /
tmpfs                     64M     0   64M   0% /dev
tmpfs                    7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/centos-root  199G  7.4G  192G   4% /etc/hosts
shm                       64M     0   64M   0% /dev/shm
/dev/rbd3                976M  2.6M  958M   1% /var/lib/www/html
tmpfs                    7.8G   12K  7.8G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs                    7.8G     0  7.8G   0% /proc/acpi
tmpfs                    7.8G     0  7.8G   0% /proc/scsi
tmpfs                    7.8G     0  7.8G   0% /sys/firmware

root@csi-rbd-restore-demo-pod:/# cd /var/lib/www/html
root@csi-rbd-restore-demo-pod:/var/lib/www/html# ls
demo  lost+found
root@csi-rbd-restore-demo-pod:/var/lib/www/html# cat demo/test.txt
snapshot test

//基于快照恢复数据功能正常


同一个pvc重复创建快照：

再次对rbd-pvc创建快照

# cat snapshot-1.yaml
---
apiVersion: snapshot.storage.k8s.io/v1beta1
kind: VolumeSnapshot
metadata:
  name: rbd-pvc-snapshot-1
spec:
  volumeSnapshotClassName: csi-rbdplugin-snapclass
  source:
    persistentVolumeClaimName: rbd-pvc
 
# kubectl apply -f snapshot-1.yaml
# kubectl get VolumeSnapshot rbd-pvc-snapshot-1
NAME                 READYTOUSE   SOURCEPVC   SOURCESNAPSHOTCONTENT   RESTORESIZE   SNAPSHOTCLASS             SNAPSHOTCONTENT                                    CREATIONTIME   AGE
rbd-pvc-snapshot-1   true         rbd-pvc                             100Gi         csi-rbdplugin-snapclass   snapcontent-b82dceb0-7ba6-4a3e-88ab-2220b729d85f   18h            18h

基于rbd-pvc-snapshot-1快照恢复pvc

# cat pvc-restore-1.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: rbd-pvc-restore-1
spec:
  storageClassName: csi-rbd-sc
  dataSource:
    name: rbd-pvc-snapshot-1
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
 
# kubectl apply -f pvc-restore-1.yaml

创建pod引用rbd-pvc-restore-1恢复的pvc

# cat pod-restore-1.yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: csi-rbd-restore-demo-pod-1
spec:
  containers:
    - name: web-server
      image: nginx
      volumeMounts:
        - name: mypvc
          mountPath: /var/lib/www/html
  volumes:
    - name: mypvc
      persistentVolumeClaim:
        claimName: rbd-pvc-restore-1
        readOnly: false
 
# kubectl apply -f pod-restore-1.yaml
NAME                         READY   STATUS    RESTARTS   AGE
csi-rbd-restore-demo-pod-1   1/1     Running   0          18h

# kubectl exec -ti csi-rbd-restore-demo-pod-1 -- bash
root@csi-rbd-restore-demo-pod-1:/# df -h
Filesystem               Size  Used Avail Use% Mounted on
overlay                  199G  7.4G  192G   4% /
tmpfs                     64M     0   64M   0% /dev
tmpfs                    7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/centos-root  199G  7.4G  192G   4% /etc/hosts
shm                       64M     0   64M   0% /dev/shm
/dev/rbd4                 99G  6.8M   99G   1% /var/lib/www/html
tmpfs                    7.8G   12K  7.8G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs                    7.8G     0  7.8G   0% /proc/acpi
tmpfs                    7.8G     0  7.8G   0% /proc/scsi
tmpfs                    7.8G     0  7.8G   0% /sys/firmware
root@csi-rbd-restore-demo-pod-1:/# cd /var/lib/www/html
root@csi-rbd-restore-demo-pod-1:/var/lib/www/html# cat demo/test.txt
snapshot test
abc
root@csi-rbd-restore-demo-pod-1:/var/lib/www/html# cat test/demo.txt
abc
 
// 至此验证扩容后的pvc，二次创建的快照恢复数据功能正常
 
// 查看第一个创建的快照中是否有后续添加的文件数据,如下数据还是第一个快照创建时数据
[root@cka-node-01 rbd]# kubectl exec -ti csi-rbd-restore-demo-pod -- bash
root@csi-rbd-restore-demo-pod:/# df -h
Filesystem               Size  Used Avail Use% Mounted on
overlay                  199G  7.4G  192G   4% /
tmpfs                     64M     0   64M   0% /dev
tmpfs                    7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/centos-root  199G  7.4G  192G   4% /etc/hosts
shm                       64M     0   64M   0% /dev/shm
/dev/rbd3                976M  2.6M  958M   1% /var/lib/www/html
tmpfs                    7.8G   12K  7.8G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs                    7.8G     0  7.8G   0% /proc/acpi
tmpfs                    7.8G     0  7.8G   0% /proc/scsi
tmpfs                    7.8G     0  7.8G   0% /sys/firmware
root@csi-rbd-restore-demo-pod:/# cd /var/lib/www/html
root@csi-rbd-restore-demo-pod:/var/lib/www/html# cat demo/test.txt
snapshot test
root@csi-rbd-restore-demo-pod:/var/lib/www/html# ls
demo  lost+found
